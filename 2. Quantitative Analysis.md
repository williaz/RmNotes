### the time value of money
- time value of money(TVM)
- at the end of the investment horizon (FV - compounding.) or at the beginning of the investment horizon (PV - discounting).
- think of I/Y as the interest rate per compounding period and N as the number of compounding periods under analysis
- keys
  - N = Number of compounding periods.
  - I/Y = Interest rate per compounding period.
  - PV = Present value.
  - FV = Future value.
  - PMT = Annuity payments, or constant periodic cash flow.
  - CPT = Compute.

- Equilibrium interest rates are the required rate of return for a particular investment
  - interest rates = discount rates, opportunity cost of current consumption, required rate of return, and the cost of capital
- The real risk-free rate of interest is a theoretical rate on a single period loan that has no expectation of inflation in it.
  - T-bill(U.S. Treasury bills) rates are nominal risk-free rates because they contain an inflation premium.
- Default risk: The risk that a borrower will not make the promised payments in a timely manner.
- Liquidity risk: The risk of receiving less than fair value for an investment if it must be sold for cash quickly.
- Maturity risk: the prices of longer-term bonds are more volatile than those of shorter-term bonds
- An annuity is a stream of **equal** cash flows that occurs at equal intervals over a given period.
  - The ordinary annuity is the most common type of annuity. It is characterized by cash flows that occur at the end of each compounding period.
  - the PMT variable is a single periodic payment
- A perpetuity is a financial instrument that pays a fixed amount of money at set intervals over an **infinite** period of time.
  - British consul bonds and most preferred stocks are examples of perpetuities since they promise fixed interest or dividend payments forever.
  - PVperp = PMT/(I/Y)
- to find the PV or FV of this cash flow stream, all we need to do is sum the PVs or FVs of the individual cash flows
- since an increase in the frequency of compounding increases the effective rate of interest, it also increases the FV of a given cash flow and decreases the PV of a given cash flow.
  - m equal the number of compounding periods per year,
  - I/Y = the annual interest rate / m
  - N = the number of years x m
- PV and FV must in diff sign

### random variables
#### LO 15.1: Describe and distinguish between continuous and discrete random variables.
- A random variable is an uncertain quantity/number.
- An outcome is an observed value of a random variable.
- An event is a single outcome or a set of outcomes.
- Mutually exclusive events are events that cannot happen at the same time.
- Exhaustive events are those that include all possible outcomes.
- A probability distribution describes the probabilities of all the possible outcomes for a random variable.
- A discrete random variable is one for which the number of possible outcomes can be counted, and for each possible outcome, there is a measurable and positive probability.
- A probability function, denoted p(x), specifies the probability that a random variable is equal to a specific value.
- A continuous random variable is one for which the number of possible outcomes is infinite, even if lower and upper bounds exist.

- It is customary to speak in terms of the probability of a range of possible price change


### distribution function
#### LO 13.2: Define and distinguish between the probability density function, the
cumulative distribution function, and the inverse cumulative distribution function.

- A probability density function (pdf) is a function, denoted f(x), that can be used to generate the probability that outcomes of a continuous distribution lie within a particular range of outcomes.
  - For a discrete distribution, it is the equivalent of a probability function for a discrete distribution.
  - for a continuous distribution, the probability
of any one particular outcome (of the infinite possible outcomes) is zero. A pdf is used to calculate the probability of an outcome between two values
- A cumulative distribution function (cdf), or simply distribution function, defines the probability that a random variable, X, takes on a value equal to or less than a specific value, x.
- inverse cumulative distribution function can be used to find the value that corresponds to a specific probability.


### discrete probability function
#### LO 15.3: Calculate the probability of an event given a discrete probability function.
- A discrete uniform random variable is one for which the probabilities for all possible outcomes for a discrete random variable are equal.

### conditional probability
#### LO 15.6: Define and calculate a conditional probability, and distinguish between conditional and unconditional probabilities.
- Unconditional probability (i.e., marginal probability) refers to the probability of an event regardless of the past or future occurrence of other events.
- A conditional probability is one where the occurrence of one event affects the probability of the occurrence of another event.
  - P(A | B), where the vertical bar (|) indicates “given,” or “conditional upon.”
  - A conditional probability of an occurrence is also called its likelihood.
- The joint probability of two events is the probability that they will both occur.
  - multiplication rule o f probability.
  - P(AB) = P(A | B) x P(B)

### independent and mutually exclusive events
#### LO 15.4: Distinguish between independent and mutually exclusive events.
- Independent events refer to events for which the occurrence of one has no influence on the occurrence of the others.
- The addition rule fo r probabilities is used to determine the probability that at least one of two events will occur.

### calculating a joint probability of anu number of independent events
#### LO 15.5: Define joint probability, describe a probability matrix, and calculate joint probabilities using probability matrices.
- Joint probabilities of independent events can be conveniently summarized using a probability matrix

- statistics
  - data
  - Statistical methods
    - Descriptive statistics are used to summarize the important characteristics of large data sets.
    - Inferential statistics, which will be discussed in subsequent topics, pertain to the procedures used to make forecasts, estimates, or judgments about a large set of data on the basis of the statistical characteristics of a smaller set (a sample).
- A population is defined as the set of all possible members of a stated group.
- A sample is defined as a subset of the population of interest.


### measure of central tendency
#### LO 16.1: Interpret and apply the mean, standard deviation, and variance of a random variable.
#### LO 16.2: Calculate the mean, standard deviation, and variance of a discrete random variable.
- The sum of the deviations of each observation in the data set from the mean is always zero.
- The median is the midpoint of a data set when the data is arranged in ascending or descending order.
- The mode is the value that occurs most frequently in a data set.
  - unimodal, bimodal, trimodal for one,two three value
- The geometric mean is often used when calculating investment returns over multiple periods or when measuring compound growth rates.
  - When calculating the geometric mean for a returns data set, it is necessary to add 1 to each value under the radical and then subtract 1 from the result.
  - The geom etric mean is always less than or equal to the arithmetic mean, and the difference increases as the dispersion o f the observations increases.

### expectations
#### LO 16.3: Interpret and calculate the expected value of a discrete random variable.
#### LO 16.5: Calculate the mean and variance of sums of variables.

- E(X^2) =/= [E(X)]^2
- The mean and variance of a distribution are defined as the first and second moments of the distribution, respectively.
- Var(X) = E[(X - E(X))^2] = E(X^2) - [E(X)]^2
- Var(aX + c) = a2 x Var(X)
- Var(X - Y) = Var(X) + Var(Y), X, Y independent
- The variance and standard deviation measure the dispersion, or volatility, of only one variable.

### covariance and correlation
#### LO 16.4: Calculate and interpret the covariance and correlation between two random variables.
- Covariance is the expected value of the product of the deviations of the two random variables from their respective expected values.
- Cov(Ri, Rj) = E{ [Ri - E(Ri)][Rj - E(Rj)] } = E(Ri, Rj) - E(Ri)*E(Rj)
- Cov(X,X) = Var(X)
- Cov(a + bX, c + dY) = b x d x Cov(X,Y)
- Correlation measures the strength of the linear relationship between two random variables.
  - ranges from -1 to +1.
  - has no units.


### central moments
#### LO 16.6: Describe the four central moments of a statistical variable or distribution: mean, variance, skewness and kurtosis.
- Raw moments are measured relative to an expected value raised to the appropriate power. 
  - The first raw moment is the mean of the distribution, which is the expected value of returns
- Central moments are measured relative to the mean (i.e., central around the mean).
  - first central moment is zero
  - second central moment is the variance of the distribution, which measures the dispersion of data.
  - third central moment measures the departure from symmetry in the distribution. This moment will equal zero for a symmetric distribution (such as the normal distribution).
    - The skewness statistic is the standardized third central moment. Skewness refers to the extent to which the distribution of data is not symmetric around its mean.
  - fourth central moment measures the degree of clustering in the distribution
    - kurtosis statistic is the standardized fourth central moment of the distribution. Kurtosis refers to the degree of peakedness or clustering in the data distribution
    - Kurtosis for the normal distribution equals 3.
      - excess kurtosis = kurtosis — 3

### skewness and kurtosis
#### LO 16.7: Interpret the skewness and kurtosis of a statistical distribution, and interpret the concepts of coskewness and cokurtosis.
- Skewness, or skew, refers to the extent to which a distribution is not symmetrical.
- Skewness affects the location of the mean, median, and mode of a distribution.
  - the mean is pulled in the direction of the skew
- Kurtosis is a measure of the degree to which a distribution is more or less “peaked” than a normal distribution. 
  - Leptokurtic describes a distribution that is more peaked than a normal distribution, 
    - have more returns clustered around the mean and more returns with large deviations from the mean (fatter tails).
  - platykurtic refers to a distribution that is less peaked (or flatter) than a normal distribution.
  - A distribution is mesokurtic if it has the same kurtosis as a normal distribution.
  - A distribution is said to exhibit excess kurtosis if it has either more or less kurtosis than the normal distribution.
- In general, greater positive kurtosis and more negative skew in returns distributions indicates increased risk.

### the best linear unbiased estimator
#### LO 16.8: Describe and interpret the best linear unbiased estimator.
- Point estimates are single (sample) values used to estimate population parameters, and the formula used to compute a point estimate is known as an estimator.
- An **unbiased** estimator is one for which the expected value of the estimator is equal to the parameter you are trying to estimate.
- An unbiased estimator is also **efficient** if the variance of its sampling distribution is smaller than all the other unbiased estimators of the parameter you are trying to estimate.
- A **consistent** estimator is one for which the accuracy of the parameter estimate increases as the sample size increases.
- A point estimate is a **linear** estimator when it can be used as a linear function of sample data.

- best linear unbiased estimator (BLUE)




- Probability distributions
  - Parametric distributions, such as a normal distribution, can be described by using a mathematical function.
  - Nonparametric distributions, such as a historical distribution, cannot be described by using a mathematical function.

#### LO 17.1: Distinguish the key properties among the following distributions: uniform distribution, Bernoulli distribution, Binomial distribution, Poisson distribution, normal distribution, lognormal distribution, Chi-squared distribution, Student s t, and F-distributions, and identify common occurrences of each distribution.


- Bernoulli distributed random variables are commonly used for assessing whether or not a company defaults during a specified time period.
- the Binomial is based on discrete events, while the Poisson is based on continuous events. [Difference between Poisson and Binomial distributions](https://math.stackexchange.com/questions/1050184/difference-between-poisson-and-binomial-distributions)
- A confidence interval is a range of values around the expected outcome within which we expect the actual outcome to be some specified percentage of the time.
- confidence intervals(X mean, s deviation)
  - The 90% confidence interval for r is X - 1.65s to X + 1.65s.
  - The 95% confidence interval for r is X - 1.96s to X + 1.96s.
  - The 99% confidence interval for r is X — 2.58s to X + 2.58s.

- A standard normal distribution (i.e., ^-distribution) is a normal distribution that has been standardized so it has a mean of zero and a standard deviation of 1 \[i.e., N"(0 , 1)].
  - z = (observation — population mean) / standard deviation


### central limit theorem
#### LO 17.2: Describe the central limit theorem and the implications it has when combining independent and identically distributed (i.i.d.) random variables.
#### LO 17.3: Describe i.i.d. random variables and the implications of the i.i.d. assumption when combining random variables. 
- The variance of the distribution of sample means is the population variance divided by the sample size.

- Student’s ^-distribution, or simply the ^-distribution, is a bell-shaped probability distribution that is symmetrical about its mean.
  - It is the appropriate distribution to use when constructing confidence intervals based on small samples (n < 30) from populations with unknown variance and a normal, or approximately normal, distribution.
  - It is defined by a single parameter, the degrees of freedom (df), where the degrees of freedom are equal to the number of sample observations minus 1, n — 1, for sample means.
  - As the degrees of freedom for the ^-distribution increase, however, its shape approaches that of the normal distribution.
  - The degrees of freedom for tests based on sample means are n — 1 because, given the mean, only n — 1 observations can be unique!!!

- The chi-square distribution is asymmetrical, bounded below by zero, and approaches the normal distribution in shape as the degrees of freedom increase.
  - The chi-squared test compares the test statistic to a critical chi-squared value at a given level of significance to determine whether to reject or fail to reject a null hypothesis.

- the hypotheses concerned with the equality of the variances of two populations are tested with an A-distributed test statistic. Hypothesis testing using a test statistic that follows an A-distribution is referred to as the A-test.
- The A-test is used under the assumption that the populations from which samples are drawn are normally distributed and that the samples are independent.

### mixture distribution
#### LO 17.4: Describe a mixture distribution and explain the creation and characteristics of mixture distributions.

































































